# AWS-Practical-Data-Science
-Develop and scaling data science projects into the cloud using Amazon SageMaker.  
-This Specialization is designed for data-focused developers, scientists, and analysts familiar with the Python and SQL programming languages who want to learn how to build, train, and deploy scalable, end-to-end ML pipelines - both automated and human-in-the-loop - in the AWS cloud.

Applied Learning Project
Specialization focused the following skills, you will be ready to:
 
• Ingest, register, and explore datasets

• Detect statistical bias in a dataset

• Automatically train and select models with AutoML

• Create machine learning features from raw data

• Save and manage features in a feature store

• Train and evaluate models using built-in algorithms and custom BERT models

• Debug, profile, and compare models to improve performance

• Build and run a complete ML pipeline end-to-end

• Optimize model performance using hyperparameter tuning

• Deploy and monitor models

• Perform data labeling at scale

• Build a human-in-the-loop pipeline to improve model performance

• Reduce cost and improve performance of data products

# Analyze Datasets and Train ML Models using AutoML
• Prepare data, detect statistical data biases, and perform feature engineering at scale to train models with pre-built algorithms.

# Build, Train, and Deploy ML Pipelines using BERT
• Store and manage machine learning features using a feature store
• Debug, profile, tune and evaluate models while tracking data lineage and model artifacts

# Optimize ML Models and Deploy Human-in-the-Loop Pipelines
• Human-in-the-Loop Pipelines
• Distributed Model Training and Hyperparameter Tuning
• Cost Savings and Performance Improvements
• A/B Testing and Model Deployment
• Data Labeling at Scale

